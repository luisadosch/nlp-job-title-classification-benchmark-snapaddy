{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/8Na26eQtu2Rs+ERWMd1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisadosch/Final-Project-snapAddy/blob/main/model2_embedding_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Github-Zugangsdaten"
      ],
      "metadata": {
        "id": "iToNPrLm7dwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "M-wmpUW1tQAx"
      },
      "outputs": [],
      "source": [
        "# GitHub-Zugangsdaten\n",
        "import pandas as pd\n",
        "\n",
        "GH_USER = \"luisadosch\"\n",
        "GH_REPO = \"Final-Project-snapAddy\"\n",
        "BRANCH = \"main\"\n",
        "\n",
        "def get_github_url(relative_path):\n",
        "    return f\"https://raw.githubusercontent.com/{GH_USER}/{GH_REPO}/{BRANCH}/{relative_path}\"\n",
        "\n",
        "\n",
        "jobs_annotated_active_df = pd.read_csv(get_github_url(\"data/processed/jobs_annotated_active.csv\"))\n",
        "\n",
        "department_df = pd.read_csv(get_github_url(\"data/raw/department-v2.csv\"))\n",
        "\n",
        "seniority_df = pd.read_csv(get_github_url(\"data/raw/seniority-v2.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Modell Seniority"
      ],
      "metadata": {
        "id": "lf3ury7l7WS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus seniority_df ---\n",
        "slabel_names = seniority_df[\"label\"].astype(str).tolist()\n",
        "slabel_texts = seniority_df[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "strue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen ---\n",
        "X = sembed_model.encode(slabel_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(\n",
        "    jobs_annotated_active_df[\"position\"].astype(str).tolist(),\n",
        "    convert_to_tensor=True\n",
        ")\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "spred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    spred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "s_eval_accuracy = accuracy_score(strue_seniority, spred_seniority)\n",
        "s_eval_macro_f1 = f1_score(strue_seniority, spred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs\")\n",
        "print(\"Accuracy:\", round(s_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(s_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(strue_seniority, spred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CpG5n2K922U",
        "outputId": "53a6bcfb-173b-41f8-d86f-8abfa55e3fd3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs\n",
            "Accuracy: 0.409\n",
            "Macro F1: 0.35\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.41      0.82      0.55        34\n",
            "      Junior       0.07      0.33      0.12        12\n",
            "        Lead       0.39      0.43      0.41       125\n",
            "  Management       0.73      0.70      0.71       192\n",
            "Professional       0.00      0.00      0.00       216\n",
            "      Senior       0.19      0.77      0.31        44\n",
            "\n",
            "    accuracy                           0.41       623\n",
            "   macro avg       0.30      0.51      0.35       623\n",
            "weighted avg       0.34      0.41      0.36       623\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block performs zero-shot classification of job seniority using embeddings. Each job title is converted into a dense vector using a pre-trained embedding model, and each possible seniority label is also mapped into the same embedding space. Cosine similarity is then computed between the job title embeddings and the label embeddings, and the label with the highest similarity is assigned to the job. This method does not require any training, making it a simple and interpretable embedding-based approach.\n",
        "\n",
        "Applying this embedding-based approach to predict seniority on ACTIVE jobs results in an accuracy of 0.409 and a macro F1 score of 0.35. The detailed classification report is as follows:\n",
        "\n",
        "| Label            | Precision | Recall | F1-score | Support |\n",
        "| ---------------- | --------- | ------ | -------- | ------- |\n",
        "| Director         | 0.41      | 0.82   | 0.55     | 34      |\n",
        "| Junior           | 0.07      | 0.33   | 0.12     | 12      |\n",
        "| Lead             | 0.39      | 0.43   | 0.41     | 125     |\n",
        "| Management       | 0.73      | 0.70   | 0.71     | 192     |\n",
        "| Professional     | 0.00      | 0.00   | 0.00     | 216     |\n",
        "| Senior           | 0.19      | 0.77   | 0.31     | 44      |\n",
        "| **Accuracy**     |           |        | **0.41** | **623** |\n",
        "| **Macro avg**    | 0.30      | 0.51   | 0.35     | 623     |\n",
        "| **Weighted avg** | 0.34      | 0.41   | 0.36     | 623     |\n",
        "\n",
        "\n",
        "\n",
        "These results indicate that while some seniority levels, such as Director and Senior, are predicted with reasonable recall, the overall performance across all classes is limited. The approach captures high-level trends but struggles with frequent and ambiguous classes like Professional, highlighting the challenges of zero-shot classification in a domain with class imbalance and short, noisy job titles."
      ],
      "metadata": {
        "id": "bFXNHMK60OA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Modell Department"
      ],
      "metadata": {
        "id": "9mt1MD0P6_pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus department_df ---\n",
        "dlabel_names = department_df[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = department_df[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "dtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen ---\n",
        "X = dembed_model.encode(dlabel_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(\n",
        "    jobs_annotated_active_df[\"position\"].astype(str).tolist(),\n",
        "    convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "dpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    dpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "d_eval_accuracy = accuracy_score(dtrue_department, dpred_department)\n",
        "d_eval_macro_f1 = f1_score(dtrue_department, dpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs\")\n",
        "print(\"Accuracy:\", round(d_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(d_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(dtrue_department, dpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6geXLpAEtfh",
        "outputId": "956d9fc7-118c-4134-d637-5d1189bbf28c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs\n",
            "Accuracy: 0.315\n",
            "Macro F1: 0.315\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.03      0.21      0.05        14\n",
            "  Business Development       0.17      0.35      0.23        20\n",
            "            Consulting       0.28      0.67      0.40        39\n",
            "      Customer Support       0.29      0.33      0.31         6\n",
            "       Human Resources       0.31      0.62      0.42        16\n",
            "Information Technology       0.35      0.31      0.32        62\n",
            "             Marketing       0.39      0.50      0.44        22\n",
            "                 Other       0.74      0.22      0.33       344\n",
            "    Project Management       0.57      0.59      0.58        39\n",
            "            Purchasing       0.02      0.07      0.03        15\n",
            "                 Sales       0.29      0.43      0.35        46\n",
            "\n",
            "              accuracy                           0.31       623\n",
            "             macro avg       0.31      0.39      0.31       623\n",
            "          weighted avg       0.55      0.31      0.34       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block applies the embedding-based zero-shot classification method to predict the department of each job. Each job title and each possible department label is converted into a dense vector using a pre-trained embedding model. Cosine similarity is then computed between the job title embeddings and the label embeddings, and the label with the highest similarity is assigned to each job. This method requires no training, making it a simple, interpretable embedding-based approach based purely on semantic similarity.\n",
        "\n",
        "Applying this embedding-based approach to predict departments on ACTIVE jobs results in an accuracy of 0.315 and a macro F1 score of 0.315. The detailed classification report is:\n",
        "| Label                    | Precision | Recall | F1-score | Support |\n",
        "|--------------------------|-----------|--------|----------|---------|\n",
        "| Administrative           | 0.03      | 0.21   | 0.05     | 14      |\n",
        "| Business Development     | 0.17      | 0.35   | 0.23     | 20      |\n",
        "| Consulting               | 0.28      | 0.67   | 0.40     | 39      |\n",
        "| Customer Support         | 0.29      | 0.33   | 0.31     | 6       |\n",
        "| Human Resources          | 0.31      | 0.62   | 0.42     | 16      |\n",
        "| Information Technology   | 0.35      | 0.31   | 0.32     | 62      |\n",
        "| Marketing                | 0.39      | 0.50   | 0.44     | 22      |\n",
        "| Other                    | 0.74      | 0.22   | 0.33     | 344     |\n",
        "| Project Management       | 0.57      | 0.59   | 0.58     | 39      |\n",
        "| Purchasing               | 0.02      | 0.07   | 0.03     | 15      |\n",
        "| Sales                    | 0.29      | 0.43   | 0.35     | 46      |\n",
        "| **Accuracy**             |           |        | **0.31** | **623** |\n",
        "| **Macro avg**            | **0.31**  | **0.39** | **0.31** | **623** |\n",
        "| **Weighted avg**         | **0.55**  | **0.31** | **0.34** | **623** |\n",
        "\n",
        "These results indicate that while some departments, such as Human Resources and Project Management, are predicted with moderate recall, the overall performance is low, particularly for highly frequent and ambiguous labels like Other. This demonstrates the limitations of zero-shot embedding-based classification in domains with unbalanced class distributions and short, noisy job titles."
      ],
      "metadata": {
        "id": "82IAor4d1a8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Modell Seniority mit synthetic Daten"
      ],
      "metadata": {
        "id": "_RoMtein730I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ORD_MAP = {\n",
        "    \"Junior\": 1.0,\n",
        "    \"Professional\": 2.0,\n",
        "    \"Senior\": 3.0,\n",
        "    \"Lead\": 4.0,\n",
        "    \"Management\": 5.0,\n",
        "    \"Director\": 6.0,\n",
        "}\n",
        "INV_ORD = {v: k for k, v in ORD_MAP.items()}"
      ],
      "metadata": {
        "id": "zj-zpLBc73ec"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_synthetic(train_df: pd.DataFrame, synthetic_csv_relpath: str) -> pd.DataFrame:\n",
        "    syn = pd.read_csv(get_github_url(synthetic_csv_relpath))\n",
        "    syn = syn[[\"position\", \"seniority\"]].copy()\n",
        "\n",
        "    id2label = {v: k for k, v in ORD_MAP.items()}\n",
        "    syn[\"label\"] = syn[\"seniority\"].map(id2label)\n",
        "    syn = syn.rename(columns={\"position\": \"text\"})\n",
        "    syn = syn.dropna(subset=[\"text\", \"label\"])\n",
        "\n",
        "    out = pd.concat([train_df[[\"text\", \"label\"]], syn[[\"text\", \"label\"]]], ignore_index=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "AjcETa1-8CY1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdf_aug = add_synthetic(seniority_df, \"data/results/gemini_synthetic.csv\")\n",
        "sdf_aug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BbAJYYMz8GAZ",
        "outputId": "e8bce11c-f440-45de-f85f-c8c4e6760e89"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text         label\n",
              "0                                                Analyst        Junior\n",
              "1                                     Analyste financier        Junior\n",
              "2                      Anwendungstechnischer Mitarbeiter        Junior\n",
              "3                                   Application Engineer        Senior\n",
              "4                                  Applications Engineer        Senior\n",
              "...                                                  ...           ...\n",
              "11309                               Juristischer Berater  Professional\n",
              "11310  Leitung Personal, Finanzen, Einkauf, IT | Folk...    Management\n",
              "11311  Verwaltungsleitung Landesspracheninstitut in d...    Management\n",
              "11312  Leitung Gebäudemanagement, Einkauf und Control...    Management\n",
              "11313                                            Dekanat        Junior\n",
              "\n",
              "[11314 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34bdea7d-2b6e-4b6e-a02f-bf98f891370c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Analyst</td>\n",
              "      <td>Junior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Analyste financier</td>\n",
              "      <td>Junior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Anwendungstechnischer Mitarbeiter</td>\n",
              "      <td>Junior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Application Engineer</td>\n",
              "      <td>Senior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Applications Engineer</td>\n",
              "      <td>Senior</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11309</th>\n",
              "      <td>Juristischer Berater</td>\n",
              "      <td>Professional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11310</th>\n",
              "      <td>Leitung Personal, Finanzen, Einkauf, IT | Folk...</td>\n",
              "      <td>Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11311</th>\n",
              "      <td>Verwaltungsleitung Landesspracheninstitut in d...</td>\n",
              "      <td>Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11312</th>\n",
              "      <td>Leitung Gebäudemanagement, Einkauf und Control...</td>\n",
              "      <td>Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11313</th>\n",
              "      <td>Dekanat</td>\n",
              "      <td>Junior</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11314 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34bdea7d-2b6e-4b6e-a02f-bf98f891370c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-34bdea7d-2b6e-4b6e-a02f-bf98f891370c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-34bdea7d-2b6e-4b6e-a02f-bf98f891370c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_06c925c5-1b9b-4be5-bcd7-6fc3bd17fccf\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('sdf_aug')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_06c925c5-1b9b-4be5-bcd7-6fc3bd17fccf button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('sdf_aug');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sdf_aug",
              "summary": "{\n  \"name\": \"sdf_aug\",\n  \"rows\": 11314,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10740,\n        \"samples\": [\n          \"Dekanat\",\n          \"Senior Solution Sales Manager\",\n          \"Verlagsleiter Aschendorff Media & Sales\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Junior\",\n          \"Senior\",\n          \"Professional\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus seniority_df ---\n",
        "slabel_names = sdf_aug[\"label\"].astype(str).tolist()\n",
        "slabel_texts = sdf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "sstrue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen ---\n",
        "X = sembed_model.encode(slabel_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(\n",
        "    jobs_annotated_active_df[\"position\"].astype(str).tolist(),\n",
        "    convert_to_tensor=True\n",
        ")\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "sspred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    sspred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "ss_eval_accuracy = accuracy_score(sstrue_seniority, sspred_seniority)\n",
        "ss_eval_macro_f1 = f1_score(sstrue_seniority, sspred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs\")\n",
        "print(\"Accuracy:\", round(ss_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(ss_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(sstrue_seniority, sspred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i10NCVNUyvKO",
        "outputId": "34660c9f-e516-4a0a-c714-e441ed5bee58"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs\n",
            "Accuracy: 0.478\n",
            "Macro F1: 0.409\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.44      0.82      0.58        34\n",
            "      Junior       0.03      0.17      0.05        12\n",
            "        Lead       0.48      0.35      0.41       125\n",
            "  Management       0.83      0.62      0.71       192\n",
            "Professional       0.57      0.40      0.47       216\n",
            "      Senior       0.17      0.41      0.24        44\n",
            "\n",
            "    accuracy                           0.48       623\n",
            "   macro avg       0.42      0.46      0.41       623\n",
            "weighted avg       0.59      0.48      0.51       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Modell Department mit synthetic Daten"
      ],
      "metadata": {
        "id": "1iphNUWaOeDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_synthetic_department(train_df: pd.DataFrame, synthetic_csv_relpath: str) -> pd.DataFrame:\n",
        "    syn = pd.read_csv(get_github_url(synthetic_csv_relpath))\n",
        "\n",
        "    # expect columns: position, department\n",
        "    syn = syn[[\"position\", \"department\"]].copy()\n",
        "    syn = syn.rename(columns={\"position\": \"text\", \"department\": \"label\"})\n",
        "    syn = syn.dropna(subset=[\"text\", \"label\"])\n",
        "\n",
        "    out = pd.concat([train_df[[\"text\", \"label\"]], syn[[\"text\", \"label\"]]], ignore_index=True)\n",
        "    return out"
      ],
      "metadata": {
        "id": "FRYxAf-5PLBu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddf_aug = add_synthetic_department(department_df, \"data/results/gemini_synthetic.csv\")\n",
        "ddf_aug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vuhrHT9WPQ9b",
        "outputId": "332e1460-ec61-4d42-f7c4-c7fcede61ec4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text               label\n",
              "0                        Adjoint directeur communication           Marketing\n",
              "1                          Advisor Strategy and Projects  Project Management\n",
              "2                                    Beratung & Projekte  Project Management\n",
              "3                           Beratung & Projektmanagement  Project Management\n",
              "4       Beratung und Projektmanagement kommunale Partner  Project Management\n",
              "...                                                  ...                 ...\n",
              "12026                               Juristischer Berater          Consulting\n",
              "12027  Leitung Personal, Finanzen, Einkauf, IT | Folk...     Human Resources\n",
              "12028  Verwaltungsleitung Landesspracheninstitut in d...      Administrative\n",
              "12029  Leitung Gebäudemanagement, Einkauf und Control...          Purchasing\n",
              "12030                                            Dekanat      Administrative\n",
              "\n",
              "[12031 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b6a8f29-1456-473d-b767-c757a07bbe3f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adjoint directeur communication</td>\n",
              "      <td>Marketing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Advisor Strategy and Projects</td>\n",
              "      <td>Project Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beratung &amp; Projekte</td>\n",
              "      <td>Project Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beratung &amp; Projektmanagement</td>\n",
              "      <td>Project Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beratung und Projektmanagement kommunale Partner</td>\n",
              "      <td>Project Management</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12026</th>\n",
              "      <td>Juristischer Berater</td>\n",
              "      <td>Consulting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12027</th>\n",
              "      <td>Leitung Personal, Finanzen, Einkauf, IT | Folk...</td>\n",
              "      <td>Human Resources</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12028</th>\n",
              "      <td>Verwaltungsleitung Landesspracheninstitut in d...</td>\n",
              "      <td>Administrative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12029</th>\n",
              "      <td>Leitung Gebäudemanagement, Einkauf und Control...</td>\n",
              "      <td>Purchasing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12030</th>\n",
              "      <td>Dekanat</td>\n",
              "      <td>Administrative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12031 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b6a8f29-1456-473d-b767-c757a07bbe3f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b6a8f29-1456-473d-b767-c757a07bbe3f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b6a8f29-1456-473d-b767-c757a07bbe3f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_b4914dfb-882e-49c2-9f80-81f250a3c5c6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ddf_aug')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b4914dfb-882e-49c2-9f80-81f250a3c5c6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ddf_aug');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ddf_aug",
              "summary": "{\n  \"name\": \"ddf_aug\",\n  \"rows\": 12031,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11515,\n        \"samples\": [\n          \"Head of Sales & Operation E-mobility Germany\",\n          \"Mediengestalter / Marketing\",\n          \"Organisationsberatung und Vertrieb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Human Resources\",\n          \"Marketing\",\n          \"Sales\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus department_df ---\n",
        "dlabel_names = ddf_aug[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = ddf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "sdtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen ---\n",
        "X = dembed_model.encode(dlabel_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(\n",
        "    jobs_annotated_active_df[\"position\"].astype(str).tolist(),\n",
        "    convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "sdpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    sdpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "sd_eval_accuracy = accuracy_score(sdtrue_department, sdpred_department)\n",
        "sd_eval_macro_f1 = f1_score(sdtrue_department, sdpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs\")\n",
        "print(\"Accuracy:\", round(sd_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(sd_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(sdtrue_department, sdpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbz4TDSoOmdr",
        "outputId": "53517397-91b6-4f44-bd18-4fdb45f3501a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs\n",
            "Accuracy: 0.496\n",
            "Macro F1: 0.44\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.03      0.21      0.05        14\n",
            "  Business Development       0.16      0.35      0.22        20\n",
            "            Consulting       0.43      0.51      0.47        39\n",
            "      Customer Support       0.55      1.00      0.71         6\n",
            "       Human Resources       0.56      0.62      0.59        16\n",
            "Information Technology       0.54      0.32      0.40        62\n",
            "             Marketing       0.48      0.45      0.47        22\n",
            "                 Other       0.78      0.53      0.64       344\n",
            "    Project Management       0.71      0.62      0.66        39\n",
            "            Purchasing       0.07      0.20      0.10        15\n",
            "                 Sales       0.63      0.48      0.54        46\n",
            "\n",
            "              accuracy                           0.50       623\n",
            "             macro avg       0.45      0.48      0.44       623\n",
            "          weighted avg       0.65      0.50      0.55       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Modell Seniority mit synthetic Daten und Oversampling"
      ],
      "metadata": {
        "id": "tq_wC7cMRFGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus sdf_aug (mit synthetischen Daten) ---\n",
        "slabel_names = sdf_aug[\"label\"].astype(str).tolist()\n",
        "slabel_texts = sdf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "slabel_texts_res, slabel_names_res = ros.fit_resample(\n",
        "    np.array(slabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    slabel_names\n",
        ")\n",
        "slabel_texts_res = slabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "sostrue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = sembed_model.encode(slabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "sospred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    sospred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "sos_eval_accuracy = accuracy_score(sostrue_seniority, sospred_seniority)\n",
        "sos_eval_macro_f1 = f1_score(sostrue_seniority, sospred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs (mit Oversampling)\")\n",
        "print(\"Accuracy:\", round(sos_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(sos_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(sostrue_seniority, sospred_seniority))"
      ],
      "metadata": {
        "id": "yhvLRp2nREgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad513a33-a33c-444d-f56e-e70c62e9ec00"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs (mit Oversampling)\n",
            "Accuracy: 0.474\n",
            "Macro F1: 0.405\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.44      0.82      0.57        34\n",
            "      Junior       0.03      0.17      0.05        12\n",
            "        Lead       0.47      0.35      0.40       125\n",
            "  Management       0.83      0.61      0.70       192\n",
            "Professional       0.56      0.40      0.47       216\n",
            "      Senior       0.16      0.39      0.23        44\n",
            "\n",
            "    accuracy                           0.47       623\n",
            "   macro avg       0.42      0.46      0.40       623\n",
            "weighted avg       0.58      0.47      0.51       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Modell Department mit synthetic Datem und Oversampling"
      ],
      "metadata": {
        "id": "HZQh9fqu4vNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Labels & Beschreibungen aus ddf_aug (mit synthetischen Daten) ---\n",
        "dlabel_names = ddf_aug[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = ddf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "dlabel_texts_res, dlabel_names_res = ros.fit_resample(\n",
        "    np.array(dlabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    dlabel_names\n",
        ")\n",
        "dlabel_texts_res = dlabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "sodtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = dembed_model.encode(dlabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "sodpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    sodpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "sod_eval_accuracy = accuracy_score(sodtrue_department, sodpred_department)\n",
        "sod_eval_macro_f1 = f1_score(sodtrue_department, sodpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs (mit Oversampling)\")\n",
        "print(\"Accuracy:\", round(sod_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(sod_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(sodtrue_department, sodpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reiFa0OB42O7",
        "outputId": "516679dd-7dc6-4b7e-b554-50e4360bdd31"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs (mit Oversampling)\n",
            "Accuracy: 0.502\n",
            "Macro F1: 0.446\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.05      0.36      0.09        14\n",
            "  Business Development       0.17      0.35      0.23        20\n",
            "            Consulting       0.42      0.51      0.46        39\n",
            "      Customer Support       0.55      1.00      0.71         6\n",
            "       Human Resources       0.53      0.62      0.57        16\n",
            "Information Technology       0.59      0.35      0.44        62\n",
            "             Marketing       0.48      0.45      0.47        22\n",
            "                 Other       0.79      0.53      0.64       344\n",
            "    Project Management       0.71      0.64      0.68        39\n",
            "            Purchasing       0.07      0.20      0.10        15\n",
            "                 Sales       0.66      0.46      0.54        46\n",
            "\n",
            "              accuracy                           0.50       623\n",
            "             macro avg       0.45      0.50      0.45       623\n",
            "          weighted avg       0.66      0.50      0.56       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Modell Seniority mit synthetic Daten und Oversampling und Modell \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\""
      ],
      "metadata": {
        "id": "7Z35W9RdJEKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus sdf_aug (mit synthetischen Daten) ---\n",
        "slabel_names = sdf_aug[\"label\"].astype(str).tolist()\n",
        "slabel_texts = sdf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "slabel_texts_res, slabel_names_res = ros.fit_resample(\n",
        "    np.array(slabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    slabel_names\n",
        ")\n",
        "slabel_texts_res = slabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m1sostrue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = sembed_model.encode(slabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m1sospred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m1sospred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m1sos_eval_accuracy = accuracy_score(m1sostrue_seniority, m1sospred_seniority)\n",
        "m1sos_eval_macro_f1 = f1_score(m1sostrue_seniority, m1sospred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\")\n",
        "print(\"Accuracy:\", round(m1sos_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m1sos_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m1sostrue_seniority, m1sospred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbIl1LaC_Fte",
        "outputId": "f919834e-3f4c-4614-abf9-f2809b50ea9e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
            "Accuracy: 0.528\n",
            "Macro F1: 0.453\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.55      0.85      0.67        34\n",
            "      Junior       0.12      0.75      0.20        12\n",
            "        Lead       0.57      0.25      0.35       125\n",
            "  Management       0.79      0.78      0.78       192\n",
            "Professional       0.57      0.45      0.50       216\n",
            "      Senior       0.16      0.30      0.21        44\n",
            "\n",
            "    accuracy                           0.53       623\n",
            "   macro avg       0.46      0.56      0.45       623\n",
            "weighted avg       0.60      0.53      0.54       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Modell Department mit synthetic Daten und Oversampling und Modell \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\""
      ],
      "metadata": {
        "id": "LQ0ucvQj_F-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Labels & Beschreibungen aus ddf_aug (mit synthetischen Daten) ---\n",
        "dlabel_names = ddf_aug[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = ddf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "dlabel_texts_res, dlabel_names_res = ros.fit_resample(\n",
        "    np.array(dlabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    dlabel_names\n",
        ")\n",
        "dlabel_texts_res = dlabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m1sodtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = dembed_model.encode(dlabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m1sodpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m1sodpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m1sod_eval_accuracy = accuracy_score(m1sodtrue_department, m1sodpred_department)\n",
        "m1sod_eval_macro_f1 = f1_score(m1sodtrue_department, m1sodpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\")\n",
        "print(\"Accuracy:\", round(m1sod_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m1sod_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m1sodtrue_department, m1sodpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVFjzdAHJDuc",
        "outputId": "a59b3fbc-d810-424a-ec66-0dcf29f82c63"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n",
            "Accuracy: 0.623\n",
            "Macro F1: 0.512\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.21      0.57      0.30        14\n",
            "  Business Development       0.22      0.55      0.31        20\n",
            "            Consulting       0.65      0.51      0.57        39\n",
            "      Customer Support       0.43      1.00      0.60         6\n",
            "       Human Resources       0.50      0.69      0.58        16\n",
            "Information Technology       0.56      0.35      0.44        62\n",
            "             Marketing       0.67      0.36      0.47        22\n",
            "                 Other       0.85      0.70      0.76       344\n",
            "    Project Management       0.42      0.69      0.52        39\n",
            "            Purchasing       0.38      0.73      0.50        15\n",
            "                 Sales       0.65      0.52      0.58        46\n",
            "\n",
            "              accuracy                           0.62       623\n",
            "             macro avg       0.50      0.61      0.51       623\n",
            "          weighted avg       0.70      0.62      0.64       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Modell Seniority mit synthetic Daten und Oversampling und Modell \"sentence-transformers/distiluse-base-multilingual-cased-v2\""
      ],
      "metadata": {
        "id": "Po6f_X6qFQ2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus sdf_aug (mit synthetischen Daten) ---\n",
        "slabel_names = sdf_aug[\"label\"].astype(str).tolist()\n",
        "slabel_texts = sdf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "slabel_texts_res, slabel_names_res = ros.fit_resample(\n",
        "    np.array(slabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    slabel_names\n",
        ")\n",
        "slabel_texts_res = slabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m2sostrue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = sembed_model.encode(slabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m2sospred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m2sospred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m2sos_eval_accuracy = accuracy_score(m2sostrue_seniority, m2sospred_seniority)\n",
        "m2sos_eval_macro_f1 = f1_score(m2sostrue_seniority, m2sospred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/distiluse-base-multilingual-cased-v2')\")\n",
        "print(\"Accuracy:\", round(m2sos_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m2sos_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m2sostrue_seniority, m2sospred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGX9gq4EFRi5",
        "outputId": "72361f5d-8a1b-4dc5-a10f-c8e28fabf31a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
            "Accuracy: 0.502\n",
            "Macro F1: 0.398\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.43      0.74      0.54        34\n",
            "      Junior       0.06      0.25      0.10        12\n",
            "        Lead       0.78      0.26      0.39       125\n",
            "  Management       0.64      0.68      0.66       192\n",
            "Professional       0.59      0.53      0.56       216\n",
            "      Senior       0.12      0.20      0.15        44\n",
            "\n",
            "    accuracy                           0.50       623\n",
            "   macro avg       0.44      0.44      0.40       623\n",
            "weighted avg       0.59      0.50      0.51       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Modell Department mit synthetic Daten und Oversampling und Modell \"sentence-transformers/distiluse-base-multilingual-cased-v2\""
      ],
      "metadata": {
        "id": "RPxKyuo8FR_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Labels & Beschreibungen aus ddf_aug (mit synthetischen Daten) ---\n",
        "dlabel_names = ddf_aug[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = ddf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "dlabel_texts_res, dlabel_names_res = ros.fit_resample(\n",
        "    np.array(dlabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    dlabel_names\n",
        ")\n",
        "dlabel_texts_res = dlabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m2sodtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"sentence-transformers/distiluse-base-multilingual-cased-v2\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = dembed_model.encode(dlabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m2sodpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m2sodpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m2sod_eval_accuracy = accuracy_score(m2sodtrue_department, m2sodpred_department)\n",
        "m2sod_eval_macro_f1 = f1_score(m2sodtrue_department, m2sodpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/distiluse-base-multilingual-cased-v2')\")\n",
        "print(\"Accuracy:\", round(m2sod_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m2sod_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m2sodtrue_department, m2sodpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBueMWvKEPXX",
        "outputId": "1d7f7d6c-f549-4716-c9ac-4c91ac58d8f4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
            "Accuracy: 0.661\n",
            "Macro F1: 0.546\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.21      0.21      0.21        14\n",
            "  Business Development       0.20      0.40      0.27        20\n",
            "            Consulting       0.64      0.72      0.67        39\n",
            "      Customer Support       0.57      0.67      0.62         6\n",
            "       Human Resources       0.41      0.69      0.51        16\n",
            "Information Technology       0.62      0.61      0.62        62\n",
            "             Marketing       0.50      0.36      0.42        22\n",
            "                 Other       0.77      0.73      0.75       344\n",
            "    Project Management       0.64      0.77      0.70        39\n",
            "            Purchasing       0.67      0.67      0.67        15\n",
            "                 Sales       0.75      0.46      0.57        46\n",
            "\n",
            "              accuracy                           0.66       623\n",
            "             macro avg       0.54      0.57      0.55       623\n",
            "          weighted avg       0.69      0.66      0.67       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Modell Seniority mit synthetic Daten und Oversampling und Modell  \"intfloat/multilingual-e5-base\""
      ],
      "metadata": {
        "id": "4ylat_FVHO-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus sdf_aug (mit synthetischen Daten) ---\n",
        "slabel_names = sdf_aug[\"label\"].astype(str).tolist()\n",
        "slabel_texts = sdf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "slabel_texts_res, slabel_names_res = ros.fit_resample(\n",
        "    np.array(slabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    slabel_names\n",
        ")\n",
        "slabel_texts_res = slabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m3sostrue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"intfloat/multilingual-e5-base\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = sembed_model.encode(slabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m3sospred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m3sospred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m3sos_eval_accuracy = accuracy_score(m3sostrue_seniority, m3sospred_seniority)\n",
        "m3sos_eval_macro_f1 = f1_score(m3sostrue_seniority, m3sospred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'intfloat/multilingual-e5-base')\")\n",
        "print(\"Accuracy:\", round(m3sos_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m3sos_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m3sostrue_seniority, m3sospred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE10lNgFHOsX",
        "outputId": "a5c7033e-7c86-497a-81b7-ca573d3fa3c0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'intfloat/multilingual-e5-base')\n",
            "Accuracy: 0.576\n",
            "Macro F1: 0.483\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.52      0.82      0.64        34\n",
            "      Junior       0.12      0.58      0.20        12\n",
            "        Lead       0.78      0.32      0.45       125\n",
            "  Management       0.75      0.77      0.76       192\n",
            "Professional       0.68      0.56      0.61       216\n",
            "      Senior       0.18      0.34      0.24        44\n",
            "\n",
            "    accuracy                           0.58       623\n",
            "   macro avg       0.50      0.57      0.48       623\n",
            "weighted avg       0.67      0.58      0.59       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Modell Department mit synthetic Daten und Oversampling und Modell  \"intfloat/multilingual-e5-base\""
      ],
      "metadata": {
        "id": "YsLJOgbxHN95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Labels & Beschreibungen aus ddf_aug (mit synthetischen Daten) ---\n",
        "dlabel_names = ddf_aug[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = ddf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "dlabel_texts_res, dlabel_names_res = ros.fit_resample(\n",
        "    np.array(dlabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    dlabel_names\n",
        ")\n",
        "dlabel_texts_res = dlabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m3sodtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"intfloat/multilingual-e5-base\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = dembed_model.encode(dlabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m3sodpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m3sodpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m3sod_eval_accuracy = accuracy_score(m3sodtrue_department, m3sodpred_department)\n",
        "m3sod_eval_macro_f1 = f1_score(m3sodtrue_department, m3sodpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'intfloat/multilingual-e5-base')\")\n",
        "print(\"Accuracy:\", round(m3sod_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m3sod_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m3sodtrue_department, m3sodpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwZdyUTiGbBO",
        "outputId": "e86f42bd-2ad4-4bea-a520-2fc815b4319b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'intfloat/multilingual-e5-base')\n",
            "Accuracy: 0.698\n",
            "Macro F1: 0.601\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.13      0.43      0.20        14\n",
            "  Business Development       0.25      0.45      0.32        20\n",
            "            Consulting       0.69      0.62      0.65        39\n",
            "      Customer Support       0.86      1.00      0.92         6\n",
            "       Human Resources       0.62      0.62      0.62        16\n",
            "Information Technology       0.64      0.52      0.57        62\n",
            "             Marketing       0.64      0.41      0.50        22\n",
            "                 Other       0.84      0.79      0.82       344\n",
            "    Project Management       0.73      0.77      0.75        39\n",
            "            Purchasing       0.44      0.80      0.57        15\n",
            "                 Sales       0.93      0.54      0.68        46\n",
            "\n",
            "              accuracy                           0.70       623\n",
            "             macro avg       0.62      0.63      0.60       623\n",
            "          weighted avg       0.75      0.70      0.72       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14. Modell Seniority mit synthetic Daten und Oversampling und Modell \"BAAI/bge-m3\""
      ],
      "metadata": {
        "id": "mseyFJWDNSai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import defaultdict\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "\n",
        "# --- Labels & Beschreibungen aus sdf_aug (mit synthetischen Daten) ---\n",
        "slabel_names = sdf_aug[\"label\"].astype(str).tolist()\n",
        "slabel_texts = sdf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "slabel_texts_res, slabel_names_res = ros.fit_resample(\n",
        "    np.array(slabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    slabel_names\n",
        ")\n",
        "slabel_texts_res = slabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m4sostrue_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "sembed_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = sembed_model.encode(slabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Seniority-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, slabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = sembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m4sospred_seniority = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m4sospred_seniority.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m4sos_eval_accuracy = accuracy_score(m4sostrue_seniority, m4sospred_seniority)\n",
        "m4sos_eval_macro_f1 = f1_score(m4sostrue_seniority, m4sospred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'BAAI/bge-m3')\")\n",
        "print(\"Accuracy:\", round(m4sos_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m4sos_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m4sostrue_seniority, m4sospred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zs-vxGT0MreA",
        "outputId": "fe5ab572-6cb9-487f-d74f-69a3c271a123"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs (mit Modell 'BAAI/bge-m3')\n",
            "Accuracy: 0.6\n",
            "Macro F1: 0.527\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.62      0.94      0.74        34\n",
            "      Junior       0.13      0.75      0.23        12\n",
            "        Lead       0.93      0.43      0.59       125\n",
            "  Management       0.83      0.81      0.82       192\n",
            "Professional       0.61      0.50      0.55       216\n",
            "      Senior       0.17      0.32      0.23        44\n",
            "\n",
            "    accuracy                           0.60       623\n",
            "   macro avg       0.55      0.63      0.53       623\n",
            "weighted avg       0.70      0.60      0.62       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15. Modell Department mit synthetic Daten und Oversampling und Modell \"BAAI/bge-m3\""
      ],
      "metadata": {
        "id": "YhcHEbmzNVsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Labels & Beschreibungen aus ddf_aug (mit synthetischen Daten) ---\n",
        "dlabel_names = ddf_aug[\"label\"].astype(str).tolist()\n",
        "dlabel_texts = ddf_aug[\"text\"].astype(str).tolist()\n",
        "\n",
        "# --- Oversampling: Labels ausgleichen ---\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "dlabel_texts_res, dlabel_names_res = ros.fit_resample(\n",
        "    np.array(dlabel_texts).reshape(-1,1),  # reshaped für RandomOverSampler\n",
        "    dlabel_names\n",
        ")\n",
        "dlabel_texts_res = dlabel_texts_res.flatten()\n",
        "\n",
        "# --- Evaluation Labels (ACTIVE Jobs) ---\n",
        "m4sodtrue_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "eval_texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "dembed_model = SentenceTransformer(\"BAAI/bge-m3\")\n",
        "\n",
        "# --- Embeddings für Label-Beschreibungen (nach Oversampling) ---\n",
        "X = dembed_model.encode(dlabel_texts_res, convert_to_tensor=True)\n",
        "\n",
        "# --- Zentroid je Department-Label berechnen ---\n",
        "by_label = defaultdict(list)\n",
        "for emb, lab in zip(X, dlabel_names_res):\n",
        "    by_label[lab].append(emb.cpu().numpy())\n",
        "\n",
        "proto_labels = list(by_label.keys())\n",
        "proto_embs = np.vstack([\n",
        "    np.mean(by_label[label], axis=0)\n",
        "    for label in proto_labels\n",
        "])\n",
        "\n",
        "# --- Embeddings für ACTIVE Jobs ---\n",
        "E = dembed_model.encode(eval_texts, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "m4sodpred_department = []\n",
        "for e in E:\n",
        "    sims = cosine_similarity(e.cpu().numpy().reshape(1, -1), proto_embs)[0]\n",
        "    m4sodpred_department.append(proto_labels[int(np.argmax(sims))])\n",
        "\n",
        "# --- Evaluation ---\n",
        "m4sod_eval_accuracy = accuracy_score(m4sodtrue_department, m4sodpred_department)\n",
        "m4sod_eval_macro_f1 = f1_score(m4sodtrue_department, m4sodpred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'BAAI/bge-m3')\")\n",
        "print(\"Accuracy:\", round(m4sod_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(m4sod_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(m4sodtrue_department, m4sodpred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E8LxyCML1u3",
        "outputId": "9f8a4936-755d-4ef2-9a21-4b03068532b2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs (mit Modell 'BAAI/bge-m3')\n",
            "Accuracy: 0.695\n",
            "Macro F1: 0.545\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.17      0.29      0.22        14\n",
            "  Business Development       0.30      0.45      0.36        20\n",
            "            Consulting       0.65      0.67      0.66        39\n",
            "      Customer Support       0.33      1.00      0.50         6\n",
            "       Human Resources       0.44      0.69      0.54        16\n",
            "Information Technology       0.65      0.42      0.51        62\n",
            "             Marketing       0.50      0.36      0.42        22\n",
            "                 Other       0.83      0.81      0.82       344\n",
            "    Project Management       0.64      0.69      0.67        39\n",
            "            Purchasing       0.52      0.80      0.63        15\n",
            "                 Sales       0.89      0.54      0.68        46\n",
            "\n",
            "              accuracy                           0.70       623\n",
            "             macro avg       0.54      0.61      0.54       623\n",
            "          weighted avg       0.73      0.70      0.70       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Full comparison: Seniority & Department (Baseline vs Synthetic vs Synthetic + Oversampling) ---\n",
        "full_comparison = pd.DataFrame({\n",
        "    \"Target\": [\n",
        "        \"Seniority (ACTIVE Jobs – Baseline)\",\n",
        "        \"Seniority (ACTIVE Jobs – with Synthetic)\",\n",
        "        \"Seniority (ACTIVE Jobs – Synthetic + Oversampling)\",\n",
        "        \"Seniority (ACTIVE Jobs – Synthetic + Oversampling mit Modell 1)\",\n",
        "        \"Seniority (ACTIVE Jobs – Synthetic + Oversampling mit Modell 2)\",\n",
        "        \"Seniority (ACTIVE Jobs – Synthetic + Oversampling mit Modell 3)\",\n",
        "        \"Seniority (ACTIVE Jobs – Syn. + Overs. mit Modell 4)\",\n",
        "        \"Department (ACTIVE Jobs – Baseline)\",\n",
        "        \"Department (ACTIVE Jobs – with Synthetic)\",\n",
        "        \"Department (ACTIVE Jobs – Synthetic + Oversampling)\",\n",
        "        \"Department (ACTIVE Jobs – Synthetic + Oversampling mit Modell 1)\",\n",
        "        \"Department (ACTIVE Jobs – Synthetic + Oversampling mit Modell 2)\",\n",
        "        \"Department (ACTIVE Jobs – Synthetic + Oversampling mit Modell 3)\",\n",
        "        \"Department (ACTIVE Jobs – Syn. + Overs. mit Modell 4)\",\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        s_eval_accuracy,      # Seniority baseline\n",
        "        ss_eval_accuracy,     # Seniority + synthetic\n",
        "        sos_eval_accuracy,    # Seniority + synthetic + oversampling\n",
        "        m1sos_eval_accuracy,  # Seniority + synthetic + oversampling mit Modell 1\n",
        "        m2sos_eval_accuracy,  # Seniority + synthetic + oversampling mit Modell 2\n",
        "        m3sos_eval_accuracy,  # Seniority + synthetic + oversampling mit Modell 3\n",
        "        m4sos_eval_accuracy,  # Seniority + synthetic + oversampling mit Modell 4\n",
        "        d_eval_accuracy,      # Department baseline\n",
        "        sd_eval_accuracy,     # Department + synthetic\n",
        "        sod_eval_accuracy,     # Department + synthetic + oversampling\n",
        "        m1sod_eval_accuracy,     # Department + synthetic + oversampling mit Modell 1\n",
        "        m2sod_eval_accuracy,     # Department + synthetic + oversampling mit Modell 2\n",
        "        m3sod_eval_accuracy,     # Department + synthetic + oversampling mit Modell 3\n",
        "        m4sod_eval_accuracy,     # Department + synthetic + oversampling mit Modell 4\n",
        "    ],\n",
        "    \"Macro F1\": [\n",
        "        s_eval_macro_f1,      # Seniority baseline\n",
        "        ss_eval_macro_f1,     # Seniority + synthetic\n",
        "        sos_eval_macro_f1,    # Seniority + synthetic + oversampling\n",
        "        m1sos_eval_macro_f1,  # Seniority + synthetic + oversampling mit Modell 1\n",
        "        m2sos_eval_macro_f1,  # Seniority + synthetic + oversampling mit Modell 2\n",
        "        m3sos_eval_macro_f1,  # Seniority + synthetic + oversampling mit Modell 3\n",
        "        m4sos_eval_macro_f1,  # Seniority + synthetic + oversampling mit Modell 4\n",
        "        d_eval_macro_f1,      # Department baseline\n",
        "        sd_eval_macro_f1,     # Department + synthetic\n",
        "        sod_eval_macro_f1,     # Department + synthetic + oversampling\n",
        "        m1sod_eval_macro_f1,     # Department + synthetic + oversampling mit Modell 1\n",
        "        m2sod_eval_macro_f1,     # Department + synthetic + oversampling mit Modell 2\n",
        "        m3sod_eval_macro_f1,     # Department + synthetic + oversampling mit Modell 3\n",
        "        m4sod_eval_macro_f1,     # Department + synthetic + oversampling mit Modell 4\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\nFull Model Comparison: Seniority & Department (Baseline vs mit Synthetic vs mit Oversampling vs mit Modell 1 vs mit Modell 2 vs mit Modell 3 vs mit Modell 4)\\n\")\n",
        "print(full_comparison)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYZe68XG0JsJ",
        "outputId": "1fffc6fd-0781-41f6-f3d1-cc1d52074d1e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full Model Comparison: Seniority & Department (Baseline vs mit Synthetic vs mit Oversampling vs mit Modell 1 vs mit Modell 2 vs mit Modell 3 vs mit Modell 4)\n",
            "\n",
            "                                               Target  Accuracy  Macro F1\n",
            "0                  Seniority (ACTIVE Jobs – Baseline)  0.409310  0.350376\n",
            "1            Seniority (ACTIVE Jobs – with Synthetic)  0.478331  0.409459\n",
            "2   Seniority (ACTIVE Jobs – Synthetic + Oversampl...  0.473515  0.404537\n",
            "3   Seniority (ACTIVE Jobs – Synthetic + Oversampl...  0.528090  0.452838\n",
            "4   Seniority (ACTIVE Jobs – Synthetic + Oversampl...  0.502408  0.398157\n",
            "5   Seniority (ACTIVE Jobs – Synthetic + Oversampl...  0.576244  0.483127\n",
            "6   Seniority (ACTIVE Jobs – Syn. + Overs. mit Mod...  0.600321  0.527059\n",
            "7                 Department (ACTIVE Jobs – Baseline)  0.314607  0.314955\n",
            "8           Department (ACTIVE Jobs – with Synthetic)  0.495987  0.440235\n",
            "9   Department (ACTIVE Jobs – Synthetic + Oversamp...  0.502408  0.446475\n",
            "10  Department (ACTIVE Jobs – Synthetic + Oversamp...  0.622793  0.511839\n",
            "11  Department (ACTIVE Jobs – Synthetic + Oversamp...  0.661316  0.545910\n",
            "12  Department (ACTIVE Jobs – Synthetic + Oversamp...  0.698234  0.600751\n",
            "13  Department (ACTIVE Jobs – Syn. + Overs. mit Mo...  0.695024  0.544908\n"
          ]
        }
      ]
    }
  ]
}