{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSpywDRRUsoSs2tAA7PskE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisadosch/Final-Project-snapAddy/blob/main/model2_embedding_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Github-Zugangsdaten"
      ],
      "metadata": {
        "id": "iToNPrLm7dwJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M-wmpUW1tQAx"
      },
      "outputs": [],
      "source": [
        "# GitHub-Zugangsdaten\n",
        "import pandas as pd\n",
        "\n",
        "GH_USER = \"luisadosch\"\n",
        "GH_REPO = \"Final-Project-snapAddy\"\n",
        "BRANCH = \"main\"\n",
        "\n",
        "def get_github_url(relative_path):\n",
        "    return f\"https://raw.githubusercontent.com/{GH_USER}/{GH_REPO}/{BRANCH}/{relative_path}\"\n",
        "\n",
        "\n",
        "jobs_annotated_active_df = pd.read_csv(get_github_url(\"data/processed/jobs_annotated_active.csv\"))\n",
        "\n",
        "department_df = pd.read_csv(get_github_url(\"data/raw/department-v2.csv\"))\n",
        "\n",
        "seniority_df = pd.read_csv(get_github_url(\"data/raw/seniority-v2.csv\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Modell Seniority"
      ],
      "metadata": {
        "id": "lf3ury7l7WS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# --- Text und Labels vorbereiten ---\n",
        "texts = jobs_annotated_active_df[\"position\"].astype(str).tolist()\n",
        "true_seniority = jobs_annotated_active_df[\"seniority\"].astype(str).tolist()\n",
        "\n",
        "# --- Label Liste ---\n",
        "seniority_labels = seniority_df[\"label\"].astype(str).tolist()\n",
        "\n",
        "# --- Embedding-Modell laden ---\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- Embeddings erzeugen ---\n",
        "text_embeddings = embed_model.encode(texts, convert_to_tensor=True)\n",
        "label_embeddings = embed_model.encode(seniority_labels, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "pred_seniority = []\n",
        "for emb in text_embeddings:\n",
        "    sims = cosine_similarity(emb.reshape(1, -1), label_embeddings)[0]\n",
        "    pred_seniority.append(seniority_labels[np.argmax(sims)])\n",
        "\n",
        "# --- Evaluation ---\n",
        "s_eval_accuracy = accuracy_score(true_seniority, pred_seniority)\n",
        "s_eval_macro_f1 = f1_score(true_seniority, pred_seniority, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Seniority Prediction on ACTIVE Jobs\")\n",
        "print(\"Accuracy:\", round(s_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(s_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(true_seniority, pred_seniority))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "858QuA-YzVhR",
        "outputId": "3d1c4bdd-8505-4f07-d5c1-1be528c85377"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Seniority Prediction on ACTIVE Jobs\n",
            "Accuracy: 0.308\n",
            "Macro F1: 0.276\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Director       0.25      0.97      0.40        34\n",
            "      Junior       0.07      0.25      0.11        12\n",
            "        Lead       0.38      0.11      0.17       125\n",
            "  Management       0.32      0.58      0.41       192\n",
            "Professional       0.00      0.00      0.00       216\n",
            "      Senior       0.48      0.68      0.56        44\n",
            "\n",
            "    accuracy                           0.31       623\n",
            "   macro avg       0.25      0.43      0.28       623\n",
            "weighted avg       0.22      0.31      0.23       623\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block performs zero-shot classification of job seniority using embeddings. Each job title is converted into a dense vector using a pre-trained embedding model, and each possible seniority label is also mapped into the same embedding space. Cosine similarity is then computed between the job title embeddings and the label embeddings, and the label with the highest similarity is assigned to the job. This method does not require any training, making it a simple and interpretable embedding-based approach.\n",
        "\n",
        "Applying this embedding-based approach to predict seniority on ACTIVE jobs results in an accuracy of 0.308 and a macro F1 score of 0.276. The detailed classification report is as follows:\n",
        "\n",
        "| Label            | Precision | Recall | F1-score | Support |\n",
        "| ---------------- | --------- | ------ | -------- | ------- |\n",
        "| Director         | 0.25      | 0.97   | 0.40     | 34      |\n",
        "| Junior           | 0.07      | 0.25   | 0.11     | 12      |\n",
        "| Lead             | 0.38      | 0.11   | 0.17     | 125     |\n",
        "| Management       | 0.32      | 0.58   | 0.41     | 192     |\n",
        "| Professional     | 0.00      | 0.00   | 0.00     | 216     |\n",
        "| Senior           | 0.48      | 0.68   | 0.56     | 44      |\n",
        "| **Accuracy**     |           |        | 0.31     | 623     |\n",
        "| **Macro avg**    | 0.25      | 0.43   | 0.28     | 623     |\n",
        "| **Weighted avg** | 0.22      | 0.31   | 0.23     | 623     |\n",
        "\n",
        "\n",
        "\n",
        "These results indicate that while some seniority levels, such as Director and Senior, are predicted with reasonable recall, the overall performance across all classes is limited. The approach captures high-level trends but struggles with frequent and ambiguous classes like Professional, highlighting the challenges of zero-shot classification in a domain with class imbalance and short, noisy job titles."
      ],
      "metadata": {
        "id": "bFXNHMK60OA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Text und Labels vorbereiten ---\n",
        "true_department = jobs_annotated_active_df[\"department\"].astype(str).tolist()\n",
        "department_labels = department_df[\"label\"].astype(str).tolist()\n",
        "\n",
        "# --- Embeddings für Text & Label ---\n",
        "label_embeddings_dep = embed_model.encode(department_labels, convert_to_tensor=True)\n",
        "\n",
        "# --- Vorhersagen ---\n",
        "pred_department = []\n",
        "for emb in text_embeddings:  # text_embeddings können wir wiederverwenden\n",
        "    sims = cosine_similarity(emb.reshape(1, -1), label_embeddings_dep)[0]\n",
        "    pred_department.append(department_labels[np.argmax(sims)])\n",
        "\n",
        "# --- Evaluation ---\n",
        "d_eval_accuracy = accuracy_score(true_department, pred_department)\n",
        "d_eval_macro_f1 = f1_score(true_department, pred_department, average=\"macro\")\n",
        "\n",
        "print(\"Embedding-based Department Prediction on ACTIVE Jobs\")\n",
        "print(\"Accuracy:\", round(d_eval_accuracy, 3))\n",
        "print(\"Macro F1:\", round(d_eval_macro_f1, 3))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(true_department, pred_department))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55loZNVL0OZx",
        "outputId": "773af751-0db6-449e-c291-9b49b6080d9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Department Prediction on ACTIVE Jobs\n",
            "Accuracy: 0.212\n",
            "Macro F1: 0.306\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Administrative       0.03      0.57      0.06        14\n",
            "  Business Development       0.17      0.35      0.23        20\n",
            "            Consulting       0.29      0.54      0.38        39\n",
            "      Customer Support       0.14      0.67      0.24         6\n",
            "       Human Resources       0.35      0.75      0.48        16\n",
            "Information Technology       0.44      0.24      0.31        62\n",
            "             Marketing       0.39      0.41      0.40        22\n",
            "                 Other       0.75      0.03      0.05       344\n",
            "    Project Management       0.34      0.59      0.43        39\n",
            "            Purchasing       0.30      0.53      0.38        15\n",
            "                 Sales       0.50      0.35      0.41        46\n",
            "\n",
            "              accuracy                           0.21       623\n",
            "             macro avg       0.34      0.46      0.31       623\n",
            "          weighted avg       0.57      0.21      0.19       623\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block applies the embedding-based zero-shot classification method to predict the department of each job. Each job title and each possible department label is converted into a dense vector using a pre-trained embedding model. Cosine similarity is then computed between the job title embeddings and the label embeddings, and the label with the highest similarity is assigned to each job. This method requires no training, making it a simple, interpretable embedding-based approach based purely on semantic similarity.\n",
        "\n",
        "Applying this embedding-based approach to predict departments on ACTIVE jobs results in an accuracy of 0.212 and a macro F1 score of 0.306. The detailed classification report is:\n",
        "| Label                  | Precision | Recall | F1-score | Support |\n",
        "| ---------------------- | --------- | ------ | -------- | ------- |\n",
        "| Administrative         | 0.03      | 0.57   | 0.06     | 14      |\n",
        "| Business Development   | 0.17      | 0.35   | 0.23     | 20      |\n",
        "| Consulting             | 0.29      | 0.54   | 0.38     | 39      |\n",
        "| Customer Support       | 0.14      | 0.67   | 0.24     | 6       |\n",
        "| Human Resources        | 0.35      | 0.75   | 0.48     | 16      |\n",
        "| Information Technology | 0.44      | 0.24   | 0.31     | 62      |\n",
        "| Marketing              | 0.39      | 0.41   | 0.40     | 22      |\n",
        "| Other                  | 0.75      | 0.03   | 0.05     | 344     |\n",
        "| Project Management     | 0.34      | 0.59   | 0.43     | 39      |\n",
        "| Purchasing             | 0.30      | 0.53   | 0.38     | 15      |\n",
        "| Sales                  | 0.50      | 0.35   | 0.41     | 46      |\n",
        "| **Accuracy**           |           |        | 0.21     | 623     |\n",
        "| **Macro avg**          | 0.34      | 0.46   | 0.31     | 623     |\n",
        "| **Weighted avg**       | 0.57      | 0.21   | 0.19     | 623     |\n",
        "\n",
        "These results indicate that while some departments, such as Human Resources and Project Management, are predicted with moderate recall, the overall performance is low, particularly for highly frequent and ambiguous labels like Other. This demonstrates the limitations of zero-shot embedding-based classification in domains with unbalanced class distributions and short, noisy job titles."
      ],
      "metadata": {
        "id": "82IAor4d1a8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Compare embedding-based results for ACTIVE jobs ---\n",
        "comparison_metrics_active = pd.DataFrame({\n",
        "    \"Target\": [\"Seniority (ACTIVE Jobs)\", \"Department (ACTIVE Jobs)\"],\n",
        "    \"Accuracy\": [s_eval_accuracy, d_eval_accuracy],\n",
        "    \"Macro F1\": [s_eval_macro_f1, d_eval_macro_f1]\n",
        "})\n",
        "\n",
        "print(\"Embedding-based Model Results (ACTIVE Jobs):\\n\")\n",
        "print(comparison_metrics_active)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olh5AJu_2Vmh",
        "outputId": "383e2746-ea43-4ad1-a4a0-1f4c9396f66e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding-based Model Results (ACTIVE Jobs):\n",
            "\n",
            "                     Target  Accuracy  Macro F1\n",
            "0   Seniority (ACTIVE Jobs)  0.308186  0.276056\n",
            "1  Department (ACTIVE Jobs)  0.211878  0.305883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block summarizes the evaluation metrics for the embedding-based zero-shot models applied to ACTIVE job titles. Accuracy represents the fraction of correct predictions, while Macro F1 accounts for class imbalance by averaging the F1-score across all labels. Presenting both metrics allows a direct comparison of performance between the Seniority and Department predictions on the same dataset.\n",
        "\n",
        "The results of the embedding-based models on ACTIVE jobs are as follows:\n",
        "\n",
        "| Target                   | Accuracy | Macro F1 |\n",
        "| ------------------------ | -------- | -------- |\n",
        "| Seniority (ACTIVE Jobs)  | 0.308    | 0.276    |\n",
        "| Department (ACTIVE Jobs) | 0.212    | 0.306    |\n",
        "\n",
        "These results indicate that the embedding-based zero-shot approach struggles with predicting both seniority and department on ACTIVE jobs. Seniority shows slightly higher accuracy for certain labels, but overall performance remains limited, reflecting the challenges of zero-shot classification in domains with noisy, short job titles and class imbalance."
      ],
      "metadata": {
        "id": "7NXdSaH83GjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "results = []\n",
        "\n",
        "def add_result(results_list, model_name, target, metrics):\n",
        "    results_list.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Target\": target,\n",
        "        \"Accuracy\": metrics[\"Accuracy\"],\n",
        "        \"Macro F1\": metrics[\"Macro F1\"]\n",
        "    })\n",
        "\n",
        "# Add embedding-based results for ACTIVE jobs\n",
        "add_result(\n",
        "    results,\n",
        "    model_name=\"Embedding-based\",\n",
        "    target=\"Seniority\",\n",
        "    metrics={\"Accuracy\": s_eval_accuracy, \"Macro F1\": s_eval_macro_f1}\n",
        ")\n",
        "\n",
        "add_result(\n",
        "    results,\n",
        "    model_name=\"Embedding-based\",\n",
        "    target=\"Department\",\n",
        "    metrics={\"Accuracy\": d_eval_accuracy, \"Macro F1\": d_eval_macro_f1}\n",
        ")\n",
        "\n",
        "save_results(results)\n",
        "\n",
        "results_df_tfidf = pd.DataFrame(results)\n",
        "results_df_tfidf\"\"\"\n"
      ],
      "metadata": {
        "id": "vWJWRGzT3JJr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}